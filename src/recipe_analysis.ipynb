{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricette definite in un formato semistrutturato, raggruppamento degli step e ingredienti in un unica stringa, funzioni di utilità"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni util e import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/navis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/navis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/navis/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/navis/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/navis/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package conll2000 to /home/navis/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.2.0/en_core_web_md-3.2.0-py3-none-any.whl (45.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 45.7 MB 21.3 MB/s eta 0:00:01   |██████▍                         | 9.2 MB 3.1 MB/s eta 0:00:12     |██████████████████████████▋     | 37.9 MB 47.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from en-core-web-md==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.4.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: setuptools in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.21.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (21.3)\n",
      "Requirement already satisfied: jinja2 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/navis/anaconda3/envs/Progetto_GDNS/lib/python3.9/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from ast import literal_eval\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "from nltk.sem import relextract\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from nltk.corpus import conll2000\n",
    "from spacy.symbols import X, NUM, VERB, NOUN\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('conll2000')\n",
    "\n",
    "\n",
    "!python -m spacy download en_core_web_md\n",
    "\n",
    "NLP = spacy.load('en_core_web_md')\n",
    "\n",
    "\n",
    "def string_recipe(i):\n",
    "    return dataset.iloc[i]['title'] + \"\\n\\n\" + dataset.iloc[i]['ingredients'] + \"\\n\\n\" + dataset.iloc[i]['step'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caricamento del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>1 small jar chipped beef, cut up.\\n4 boned chi...</td>\n",
       "      <td>Place chipped beef on bottom of baking dish. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>2 (16 oz.) pkg. frozen corn.\\n1 (8 oz.) pkg. c...</td>\n",
       "      <td>In a slow cooker, combine all ingredients. Cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>1 large whole chicken.\\n2 (10 1/2 oz.) cans ch...</td>\n",
       "      <td>Boil and debone chicken. Put bite size pieces ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>1 c. peanut butter.\\n3/4 c. graham cracker cru...</td>\n",
       "      <td>Combine first four ingredients and press in 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cheeseburger Potato Soup</td>\n",
       "      <td>6 baking potatoes.\\n1 lb. of extra lean ground...</td>\n",
       "      <td>Wash potatoes; prick several times with a fork...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  \\\n",
       "index                             \n",
       "1         Jewell Ball'S Chicken   \n",
       "2                   Creamy Corn   \n",
       "3                 Chicken Funny   \n",
       "4          Reeses Cups(Candy)     \n",
       "5      Cheeseburger Potato Soup   \n",
       "\n",
       "                                             ingredients  \\\n",
       "index                                                      \n",
       "1      1 small jar chipped beef, cut up.\\n4 boned chi...   \n",
       "2      2 (16 oz.) pkg. frozen corn.\\n1 (8 oz.) pkg. c...   \n",
       "3      1 large whole chicken.\\n2 (10 1/2 oz.) cans ch...   \n",
       "4      1 c. peanut butter.\\n3/4 c. graham cracker cru...   \n",
       "5      6 baking potatoes.\\n1 lb. of extra lean ground...   \n",
       "\n",
       "                                                    step  \n",
       "index                                                     \n",
       "1      Place chipped beef on bottom of baking dish. P...  \n",
       "2      In a slow cooker, combine all ingredients. Cov...  \n",
       "3      Boil and debone chicken. Put bite size pieces ...  \n",
       "4      Combine first four ingredients and press in 13...  \n",
       "5      Wash potatoes; prick several times with a fork...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckeye Candy\n",
      "\n",
      "1 box powdered sugar.\n",
      "8 oz. soft butter.\n",
      "1 (8 oz.) peanut butter.\n",
      "paraffin.\n",
      "12 oz. chocolate chips\n",
      "\n",
      "Mix sugar, butter and peanut butter. Roll into balls and place on cookie sheet. Set in freezer for at least 30 minutes. Melt chocolate chips and paraffin in double boiler. Using a toothpick, dip balls 3/4 of way into chocolate chip and paraffin mixture to make them look like buckeyes.\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\n",
    "    Path(\"../data/test_dataset.csv\").resolve(), \n",
    "    index_col=[0], \n",
    "    names=[\"index\", \"title\",\"ingredients\",\"step\"], \n",
    "    usecols=[0,1,2,3]\n",
    "    )\n",
    "\n",
    "for index in range(len(dataset)):\n",
    "    dataset.iloc[index]['ingredients'] = \".\\n\".join(literal_eval(dataset.iloc[index]['ingredients']))\n",
    "    dataset.iloc[index]['step'] = \" \".join(literal_eval(dataset.iloc[index]['step']))\n",
    "\n",
    "display(dataset.head())\n",
    "print(string_recipe(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione delle abbreviazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fase iniziale di ritrovamento del set di abbreviazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gal.', 'sq.', 'tsp.', 'pkg.', 'pt.', 'c.', 'oz.', 'No.', 'tbsp.', 'Tbsp.', 'lb.', 'qt.'}\n"
     ]
    }
   ],
   "source": [
    "abbrv_dataset = pd.read_csv(\n",
    "    Path(\"../data/test_dataset.csv\").resolve(), \n",
    "    index_col=[0], \n",
    "    names=[\"index\", \"title\",\"ingredients\",\"step\"], \n",
    "    usecols=[0,1,2,3]\n",
    "    )\n",
    "\n",
    "abbrv = set()\n",
    "for index in range(len(dataset)):\n",
    "    abbrv_dataset.iloc[index]['ingredients'] = \" \".join(literal_eval(abbrv_dataset.iloc[index]['ingredients']))\n",
    "    for element in re.findall(r\"[A-Za-z]*\\.\", abbrv_dataset.iloc[index]['ingredients']):\n",
    "        abbrv.add(element)\n",
    "    \n",
    "print(abbrv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rimozione delle abbreviazioni in quanto possono essere dannose per il processo di tokenizzazione. Es pkg. ---> package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_abbreviations(ingredients_string):\n",
    "    __ABBREVIATIONS__ = {\n",
    "        'pkg.'  :   'package',\n",
    "        'tsb.'  :   'tablespoon',\n",
    "        'no.'   :   'number',\n",
    "        'pt.'   :   'pint',\n",
    "        'no.'   :   'number',\n",
    "        'gal.'  :   'gallon',\n",
    "        'tbsp.' :   'tablespoon',\n",
    "        'sq.'   :   'square',\n",
    "        'oz.'   :   'ounce',\n",
    "        'lb.'   :   'pound',\n",
    "        'qt.'   :   'quart',\n",
    "        'c.'    :   'cup',\n",
    "        'tsp.'  :   'teaspoon'\n",
    "    }\n",
    "    for item, value in __ABBREVIATIONS__.items():\n",
    "        ingredients_string = ingredients_string.lower().replace(item, value)\n",
    "    return ingredients_string\n",
    "\n",
    "\n",
    "for index in range(len(dataset)):\n",
    "    dataset.iloc[index]['ingredients'] = expand_abbreviations(dataset.iloc[index]['ingredients'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence splitting\n",
    "Il contenuto delle colonne 'ingredients' e 'step' verrà suddiviso in frasi. In precedenza i periodi contenuti nelle singole celle sono stati formattati in modo tale da renderli riconoscibili e facilmente suddivisibili in frasi ben separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 box powdered sugar.', '8 ounce soft butter.', '1 (8 ounce) peanut butter.', 'paraffin.', '12 ounce chocolate chips']\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(dataset)):\n",
    "     dataset.iloc[index]['ingredients'] = (sent_tokenize(dataset.iloc[index]['ingredients']))\n",
    "print(dataset.iloc[10]['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mix sugar, butter and peanut butter.', 'Roll into balls and place on cookie sheet.', 'Set in freezer for at least 30 minutes.', 'Melt chocolate chips and paraffin in double boiler.', 'Using a toothpick, dip balls 3/4 of way into chocolate chip and paraffin mixture to make them look like buckeyes.']\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(dataset)):\n",
    "     dataset.iloc[index]['step'] = (sent_tokenize(dataset.iloc[index]['step']))\n",
    "print(dataset.iloc[10]['step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rimozione quantità doppie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_reg = r'\\d*\\s*\\(.*\\)'\n",
    "\n",
    "for index in range(len(dataset)):\n",
    "    for value in range(len(dataset.iloc[index]['ingredients'])):\n",
    "        elements = re.findall(dr_reg, dataset.iloc[index]['ingredients'][value])\n",
    "        for e in elements:\n",
    "            new_string = dataset.iloc[index]['ingredients'][value].replace(e,e[e.find(\"(\")+1: e.find(\")\")].strip())\n",
    "            dataset.iloc[index]['ingredients'][value] = new_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALISI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words removal\n",
    "Nella colonna 'step' troviamo una serie di passaggi da compiere per creare la ricetta. Questi passaggi sono scritti in linguaggio naturale e possono essere semplificati rimuovendo delle parole dette stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTINAL -> Risultati in swr_dataset\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "swr_dataset = dataset.copy(deep=True)\n",
    "\n",
    "tk = lambda x,st: ' '.join([w for w in x if w not in st])\n",
    "for index in range(len(dataset)):\n",
    "    swr_dataset.iloc[index]['step'] = [tk(word_tokenize(sent), stop_words) for sent in dataset.iloc[index]['step']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming e Lemming\n",
    "Questi due processi potrebbero portare valore all'analisi del dominio. Il codice per entrambi viene proposto qui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTINAL -> Risultati in lem_dataset\"\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lem_dataset = swr_dataset.copy(deep=True)\n",
    "\n",
    "for index in range(len(swr_dataset)):\n",
    "    lem_dataset.iloc[index]['step'] = stem_sent = [' '.join([lemmatizer.lemmatize(w) for w in word_tokenize(sent)]) for sent in swr_dataset.iloc[index]['step']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTINAL -> Risultati in stm_dataset\"\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stm_dataset = lem_dataset.copy(deep=True)\n",
    "\n",
    "for index in range(len(lem_dataset)):\n",
    "    stm_dataset.iloc[index]['step'] = [' '.join([stemmer.stem(w) for w in word_tokenize(sent)]) for sent in lem_dataset.iloc[index]['step']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frasi originali\n",
      "\n",
      "['Mix sugar, butter and peanut butter.', 'Roll into balls and place on cookie sheet.', 'Set in freezer for at least 30 minutes.', 'Melt chocolate chips and paraffin in double boiler.', 'Using a toothpick, dip balls 3/4 of way into chocolate chip and paraffin mixture to make them look like buckeyes.']\n",
      "\n",
      "Stop word removal\n",
      "\n",
      "['Mix sugar , butter peanut butter .', 'Roll balls place cookie sheet .', 'Set freezer least 30 minutes .', 'Melt chocolate chips paraffin double boiler .', 'Using toothpick , dip balls 3/4 way chocolate chip paraffin mixture make look like buckeyes .']\n",
      "\n",
      "Stop word e lemming\n",
      "\n",
      "['Mix sugar , butter peanut butter .', 'Roll ball place cookie sheet .', 'Set freezer least 30 minute .', 'Melt chocolate chip paraffin double boiler .', 'Using toothpick , dip ball 3/4 way chocolate chip paraffin mixture make look like buckeye .']\n",
      "\n",
      "Stop word lemming e stemming\n",
      "\n",
      "['mix sugar , butter peanut butter .', 'roll ball place cooki sheet .', 'set freezer least 30 minut .', 'melt chocol chip paraffin doubl boiler .', 'use toothpick , dip ball 3/4 way chocol chip paraffin mixtur make look like buckey .']\n"
     ]
    }
   ],
   "source": [
    "print(\"Frasi originali\\n\")\n",
    "print(dataset.iloc[10]['step'])\n",
    "print(\"\\nStop word removal\\n\")\n",
    "print(swr_dataset.iloc[10]['step'])\n",
    "print(\"\\nStop word e lemming\\n\")\n",
    "print(lem_dataset.iloc[10]['step'])\n",
    "print(\"\\nStop word lemming e stemming\\n\")\n",
    "print(stm_dataset.iloc[10]['step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entityt Extraction, Relation Extraction e POS tagging con SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_dataset = dataset.copy(deep=True)\n",
    "       \n",
    "for index in range(len(dataset)):\n",
    "    spacy_dataset.iloc[index]['ingredients'] = [NLP(element) for element in dataset.iloc[index]['ingredients']]\n",
    "    spacy_dataset.iloc[index]['step'] = [NLP(element) for element in dataset.iloc[index]['step']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __pprintsp__(dataset, index, column, value, extend=False):\n",
    "    displacy.render(dataset.iloc[index][column][value], style='dep')\n",
    "    print(dataset.iloc[index][column][value])\n",
    "    displacy.render(dataset.iloc[index][column][value], style='ent')\n",
    "    if extend:\n",
    "        for token in dataset.iloc[index][column][value]:\n",
    "            print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop)\n",
    "\n",
    "def pprint_spacyd_all(dataset, index, column, extend=False):\n",
    "    for v in range(len(dataset.iloc[index][column])):\n",
    "        __pprintsp__(dataset, index, column, v, extend)\n",
    "            \n",
    "def pprint_spacyd(dataset, index, column, value, extend=False):\n",
    "    __pprintsp__(dataset, index, column, value, extend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi degli ingredienti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_food(word):\n",
    "    syns = wn.synsets(str(word), pos = wn.NOUN)\n",
    "    for syn in syns:\n",
    "        if 'food' in syn.lexname():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "#Root generation\n",
    "\n",
    "__SIZES__ = [\n",
    "       'package',\n",
    "       'tablespoon',\n",
    "       'number',\n",
    "       'pint',\n",
    "       'number',\n",
    "       'gallon',\n",
    "       'tablespoon',\n",
    "       'square',\n",
    "       'ounce',\n",
    "       'pound',\n",
    "       'quart',\n",
    "       'cup',\n",
    "       'teaspoon',\n",
    "       'can'\n",
    "]\n",
    "\n",
    "\n",
    "class Ingredient:\n",
    "    def __init__(self, full_text):\n",
    "        self.name=\"\"\n",
    "        self.size=\"\"\n",
    "        self.quantity=\"\"\n",
    "        self.size=\"\"\n",
    "        self.adj=[]\n",
    "        self.original=full_text\n",
    "    def __str__(self):\n",
    "        return f\"Name: {self.name}\\nAjdectives: {self.adj}\\nQuantity: {self.quantity} {self.size}\\nOriginal: {self.original}\"\n",
    "\n",
    "for index in range(6,10):\n",
    "    for v in range(4):\n",
    "\n",
    "        ingredient = spacy_dataset.iloc[index]['ingredients'][v]\n",
    "        pprint_spacyd(spacy_dataset, index, 'ingredients', v)\n",
    "\n",
    "        IGN = Ingredient(ingredient.text)\n",
    "        ROOT_NODE = [token for token in ingredient if token.dep_ == 'ROOT'][0]\n",
    "        \n",
    "\n",
    "        if (ROOT_NODE.pos == VERB):\n",
    "                IGN.adj.append(ROOT_NODE.text)\n",
    "        else:\n",
    "                IGN.name = ROOT_NODE.text\n",
    "                \n",
    "        stack = [element for element in ROOT_NODE.children]\n",
    "\n",
    "        while len(stack)!=0:\n",
    "            CURRENT_NODE = stack.pop()\n",
    "\n",
    "            if (CURRENT_NODE.pos == X) or (CURRENT_NODE.pos == NUM):\n",
    "                    IGN.quantity += \" \" + CURRENT_NODE.text\n",
    "            else:\n",
    "                if CURRENT_NODE.text.lower() in  __SIZES__:\n",
    "                    IGN.size += \" \" + CURRENT_NODE.text\n",
    "\n",
    "                if ((CURRENT_NODE.dep_ == 'compound') or (CURRENT_NODE.dep_ == 'dobj') or (CURRENT_NODE.dep_ == 'pobj')) and is_food(CURRENT_NODE.text) and (CURRENT_NODE.text.lower() not in  __SIZES__):\n",
    "                    IGN.name = CURRENT_NODE.text + \" \" + IGN.name\n",
    "\n",
    "                if (CURRENT_NODE.dep_ == 'amod') or (CURRENT_NODE.dep_ == 'appos'):\n",
    "                    if is_food(CURRENT_NODE.text):\n",
    "                        IGN.name = CURRENT_NODE.text + \" \" + IGN.name\n",
    "                    else:\n",
    "                        IGN.adj.append(CURRENT_NODE.text)         \n",
    "\n",
    "            stack += [element for element in CURRENT_NODE.children]   \n",
    "\n",
    "        print(IGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b38470ce2bcd422f9a9ed6e845463e60-0\" class=\"displacy\" width=\"2325\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Cover</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">cook</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">slowly,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">stirring</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">occasionally</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">30</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">minutes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">or</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">until</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">meat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">tender.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b38470ce2bcd422f9a9ed6e845463e60-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,352.0 205.0,352.0 205.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b38470ce2bcd422f9a9ed6e845463e60-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M205.0,441.5 L213.0,429.5 197.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b38470ce2bcd422f9a9ed6e845463e60-0-1\" stroke-width=\"2px\" d=\"M70,439.5 C70,264.5 385.0,264.5 385.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b38470ce2bcd422f9a9ed6e845463e60-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M385.0,441.5 L393.0,429.5 377.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b38470ce2bcd422f9a9ed6e845463e60-0-2\" stroke-width=\"2px\" d=\"M420,439.5 C420,352.0 555.0,352.0 555.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b38470ce2bcd422f9a9ed6e845463e60-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M555.0,441.5 L563.0,429.5 547.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b38470ce2bcd422f9a9ed6e845463e60-0-3\" stroke-width=\"2px\" d=\"M70,439.5 C70,89.5 745.0,89.5 745.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b38470ce2bcd422f9a9ed6e845463e60-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,441.5 L753.0,429.5 737.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b38470ce2bcd422f9a9ed6e845463e60-0-4\" stroke-width=\"2px\" d=\"M945,439.5 C945,352.0 1080.0,352.0 1080.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b38470ce2bcd422f9a9ed6e845463e60-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,441.5 L937,429.5 953,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b38470ce2bcd422f9a9ed6e845463e60-0-5\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,352.0 1255.0,352.0 1255.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b38470ce2bcd422f9a9ed6e845463e60-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,441.5 L1112,429.5 1128,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b38470ce2bcd422f9a9ed6e845463e60-0-6\" stroke-width=\"2px\" d=\"M770,439.5 C770,177.0 1265.0,177.0 1265.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b38470ce2bcd422f9a9ed6e845463e60-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1265.0,441.5 L1273.0,429.5 1257.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b38470ce2bcd422f9a9ed6e845463e60-0-7\" stroke-width=\"2px\" d=\"M770,439.5 C770,89.5 1445.0,89.5 1445.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b38470ce2bcd422f9a9ed6e845463e60-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1445.0,441.5 L1453.0,429.5 1437.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b38470ce2bcd422f9a9ed6e845463e60-0-8\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,264.5 1960.0,264.5 1960.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b38470ce2bcd422f9a9ed6e845463e60-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,441.5 L1637,429.5 1653,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b38470ce2bcd422f9a9ed6e845463e60-0-9\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,352.0 1955.0,352.0 1955.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b38470ce2bcd422f9a9ed6e845463e60-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,441.5 L1812,429.5 1828,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b38470ce2bcd422f9a9ed6e845463e60-0-10\" stroke-width=\"2px\" d=\"M770,439.5 C770,2.0 1975.0,2.0 1975.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b38470ce2bcd422f9a9ed6e845463e60-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1975.0,441.5 L1983.0,429.5 1967.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b38470ce2bcd422f9a9ed6e845463e60-0-11\" stroke-width=\"2px\" d=\"M1995,439.5 C1995,352.0 2130.0,352.0 2130.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b38470ce2bcd422f9a9ed6e845463e60-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2130.0,441.5 L2138.0,429.5 2122.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cover and cook slowly, stirring occasionally 30 minutes or until meat is tender.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Cover and cook slowly, stirring occasionally \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    30 minutes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " or until meat is tender.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_spacyd(spacy_dataset, 25, 'step', 4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fef19a476ade33c91668e3897e6fa668c17f7c4a539d9a83d441085d42ee0ef"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
